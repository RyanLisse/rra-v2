/**
 * Performance Enhancer
 *
 * Advanced performance optimization utilities for the entire system.
 * Includes memory management, database optimization, and caching strategies.
 */

import { performance } from 'node:perf_hooks';

/**
 * Performance optimization configuration
 */
export interface PerformanceConfig {
  enableMemoryOptimization: boolean;
  enableDatabaseOptimization: boolean;
  enableCaching: boolean;
  workerThreads: number;
  maxMemoryUsage: number; // MB
  gcThreshold: number; // Memory usage percentage to trigger GC
  cacheSize: number; // Max items in cache
  cacheTTL: number; // Cache TTL in milliseconds
}

/**
 * Memory pool for reusing objects
 */
class ObjectPool<T> {
  private pool: T[] = [];
  private createFn: () => T;
  private resetFn: (obj: T) => void;
  private maxSize: number;

  constructor(createFn: () => T, resetFn: (obj: T) => void, maxSize = 100) {
    this.createFn = createFn;
    this.resetFn = resetFn;
    this.maxSize = maxSize;
  }

  acquire(): T {
    if (this.pool.length > 0) {
      const item = this.pool.pop();
      return item ?? this.createFn();
    }
    return this.createFn();
  }

  release(obj: T): void {
    if (this.pool.length < this.maxSize) {
      this.resetFn(obj);
      this.pool.push(obj);
    }
  }

  clear(): void {
    this.pool.length = 0;
  }

  size(): number {
    return this.pool.length;
  }
}

/**
 * LRU Cache implementation
 */
class LRUCache<K, V> {
  private cache = new Map<K, V>();
  private maxSize: number;
  private ttl: number;
  private timers = new Map<K, NodeJS.Timeout>();

  constructor(maxSize = 1000, ttl = 300000) {
    this.maxSize = maxSize;
    this.ttl = ttl;
  }

  get(key: K): V | undefined {
    const value = this.cache.get(key);
    if (value) {
      // Move to end (most recently used)
      this.cache.delete(key);
      this.cache.set(key, value);

      // Reset TTL
      this.resetTimer(key);
    }
    return value;
  }

  set(key: K, value: V): void {
    // Remove oldest if at capacity
    if (this.cache.size >= this.maxSize && !this.cache.has(key)) {
      const firstKey = this.cache.keys().next().value;
      this.delete(firstKey);
    }

    this.cache.set(key, value);
    this.resetTimer(key);
  }

  delete(key: K): boolean {
    const timer = this.timers.get(key);
    if (timer) {
      clearTimeout(timer);
      this.timers.delete(key);
    }
    return this.cache.delete(key);
  }

  clear(): void {
    this.timers.forEach((timer) => clearTimeout(timer));
    this.timers.clear();
    this.cache.clear();
  }

  size(): number {
    return this.cache.size;
  }

  private resetTimer(key: K): void {
    const existingTimer = this.timers.get(key);
    if (existingTimer) {
      clearTimeout(existingTimer);
    }

    const timer = setTimeout(() => {
      this.delete(key);
    }, this.ttl);

    this.timers.set(key, timer);
  }
}

/**
 * Performance enhancer class
 */
export class PerformanceEnhancer {
  private config: PerformanceConfig;
  private caches = new Map<string, LRUCache<any, any>>();
  private pools = new Map<string, ObjectPool<any>>();
  private metrics = {
    cacheHits: 0,
    cacheMisses: 0,
    poolAcquisitions: 0,
    poolReleases: 0,
    gcTriggers: 0,
  };

  constructor(config: Partial<PerformanceConfig> = {}) {
    this.config = {
      enableMemoryOptimization: true,
      enableDatabaseOptimization: true,
      enableCaching: true,
      workerThreads: Math.max(
        1,
        Math.floor(require('node:os').cpus().length / 2),
      ),
      maxMemoryUsage: 1024, // 1GB
      gcThreshold: 85, // 85%
      cacheSize: 1000,
      cacheTTL: 300000, // 5 minutes
      ...config,
    };

    this.initializeOptimizations();
  }

  /**
   * Initialize all performance optimizations
   */
  private initializeOptimizations(): void {
    if (this.config.enableMemoryOptimization) {
      this.setupMemoryOptimization();
    }

    if (this.config.enableCaching) {
      this.setupCaching();
    }

    if (this.config.enableDatabaseOptimization) {
      this.setupDatabaseOptimization();
    }
  }

  /**
   * Setup memory optimization
   */
  private setupMemoryOptimization(): void {
    // Monitor memory usage and trigger GC when needed
    setInterval(() => {
      const memUsage = process.memoryUsage();
      const usedMB = memUsage.heapUsed / 1024 / 1024;
      const totalMB = memUsage.heapTotal / 1024 / 1024;
      const usagePercent = (usedMB / this.config.maxMemoryUsage) * 100;

      if (usagePercent > this.config.gcThreshold && global.gc) {
        global.gc();
        this.metrics.gcTriggers++;
      }
    }, 10000); // Check every 10 seconds

    // Setup object pools for common objects
    this.createObjectPool(
      'documentChunk',
      () => ({ content: '', metadata: {}, pageNumber: null }),
      (obj) => {
        obj.content = '';
        obj.metadata = {};
        obj.pageNumber = null;
      },
    );

    this.createObjectPool(
      'searchResult',
      () => ({ id: '', score: 0, content: '', metadata: {} }),
      (obj) => {
        obj.id = '';
        obj.score = 0;
        obj.content = '';
        obj.metadata = {};
      },
    );
  }

  /**
   * Setup caching system
   */
  private setupCaching(): void {
    // Create caches for different data types
    this.createCache('documents', this.config.cacheSize, this.config.cacheTTL);
    this.createCache(
      'embeddings',
      this.config.cacheSize * 2,
      this.config.cacheTTL * 2,
    );
    this.createCache(
      'searchResults',
      this.config.cacheSize,
      this.config.cacheTTL / 2,
    );
    this.createCache(
      'chatHistory',
      this.config.cacheSize / 2,
      this.config.cacheTTL,
    );
  }

  /**
   * Setup database optimization
   */
  private setupDatabaseOptimization(): void {
    // This would typically include connection pooling optimization
    console.log('üóÉÔ∏è Database optimization initialized');
  }

  /**
   * Create a new cache
   */
  createCache(
    name: string,
    maxSize?: number,
    ttl?: number,
  ): LRUCache<any, any> {
    const cache = new LRUCache(
      maxSize || this.config.cacheSize,
      ttl || this.config.cacheTTL,
    );
    this.caches.set(name, cache);
    return cache;
  }

  /**
   * Get cache by name
   */
  getCache(name: string): LRUCache<any, any> | undefined {
    return this.caches.get(name);
  }

  /**
   * Cache get with metrics
   */
  cacheGet<T>(cacheName: string, key: string): T | undefined {
    const cache = this.caches.get(cacheName);
    if (!cache) return undefined;

    const value = cache.get(key);
    if (value) {
      this.metrics.cacheHits++;
    } else {
      this.metrics.cacheMisses++;
    }
    return value;
  }

  /**
   * Cache set with metrics
   */
  cacheSet<T>(cacheName: string, key: string, value: T): void {
    const cache = this.caches.get(cacheName);
    if (cache) {
      cache.set(key, value);
    }
  }

  /**
   * Create object pool
   */
  createObjectPool<T>(
    name: string,
    createFn: () => T,
    resetFn: (obj: T) => void,
    maxSize?: number,
  ): ObjectPool<T> {
    const pool = new ObjectPool(createFn, resetFn, maxSize || 100);
    this.pools.set(name, pool);
    return pool;
  }

  /**
   * Get object from pool
   */
  poolAcquire<T>(poolName: string): T | undefined {
    const pool = this.pools.get(poolName);
    if (pool) {
      this.metrics.poolAcquisitions++;
      return pool.acquire();
    }
    return undefined;
  }

  /**
   * Return object to pool
   */
  poolRelease<T>(poolName: string, obj: T): void {
    const pool = this.pools.get(poolName);
    if (pool) {
      this.metrics.poolReleases++;
      pool.release(obj);
    }
  }

  /**
   * Optimize database queries
   */
  async optimizeDatabase(): Promise<{
    optimizations: string[];
    performance: any;
  }> {
    const optimizations: string[] = [];
    const startTime = performance.now();

    try {
      // Import database modules only when needed
      const { db } = await import('@/lib/db');
      const { sql } = await import('drizzle-orm');

      // Analyze and optimize slow queries
      await this.analyzeSlowQueries();
      optimizations.push('Analyzed slow queries');

      // Update database statistics
      await db.execute(sql`ANALYZE;`);
      optimizations.push('Updated database statistics');

      // Check and suggest index optimizations
      const indexSuggestions = await this.analyzeIndexUsage();
      optimizations.push(...indexSuggestions);

      const endTime = performance.now();

      return {
        optimizations,
        performance: {
          duration: endTime - startTime,
          timestamp: new Date().toISOString(),
        },
      };
    } catch (error) {
      console.error('Database optimization failed:', error);
      return {
        optimizations: [
          'Database optimization failed (database not available)',
        ],
        performance: {
          duration: performance.now() - startTime,
          timestamp: new Date().toISOString(),
          error: error instanceof Error ? error.message : String(error),
        },
      };
    }
  }

  /**
   * Analyze slow queries
   */
  private async analyzeSlowQueries(): Promise<void> {
    try {
      const slowQueries = await db.execute(sql`
        SELECT 
          query,
          calls,
          total_time,
          mean_time,
          rows
        FROM pg_stat_statements
        WHERE mean_time > 100
        ORDER BY mean_time DESC
        LIMIT 10
      `);

      if (slowQueries.length > 0) {
        console.log(`‚ö†Ô∏è Found ${slowQueries.length} slow queries`);
      }
    } catch (error) {
      // pg_stat_statements might not be available
      console.log('üìä pg_stat_statements not available for query analysis');
    }
  }

  /**
   * Analyze index usage
   */
  private async analyzeIndexUsage(): Promise<string[]> {
    const suggestions: string[] = [];

    try {
      const indexStats = await db.execute(sql`
        SELECT 
          schemaname,
          tablename,
          indexname,
          idx_scan,
          idx_tup_read,
          idx_tup_fetch
        FROM pg_stat_user_indexes
        WHERE idx_scan < 100
        ORDER BY idx_scan ASC
        LIMIT 10
      `);

      if (indexStats.length > 0) {
        suggestions.push(
          `Found ${indexStats.length} potentially unused indexes`,
        );
      }

      // Check for missing indexes on foreign keys
      const missingIndexes = await db.execute(sql`
        SELECT 
          c.conname,
          t.relname AS table_name,
          a.attname AS column_name
        FROM pg_constraint c
        JOIN pg_class t ON c.conrelid = t.oid
        JOIN pg_attribute a ON a.attrelid = t.oid AND a.attnum = ANY(c.conkey)
        WHERE c.contype = 'f'
        AND NOT EXISTS (
          SELECT 1 FROM pg_index i
          WHERE i.indrelid = c.conrelid
          AND a.attnum = ANY(i.indkey)
        )
        LIMIT 5
      `);

      if (missingIndexes.length > 0) {
        suggestions.push(
          `Found ${missingIndexes.length} foreign keys without indexes`,
        );
      }
    } catch (error) {
      suggestions.push('Could not analyze index usage');
    }

    return suggestions;
  }

  /**
   * Batch process with worker threads
   */
  async batchProcess<T, R>(
    items: T[],
    processor: (item: T) => Promise<R>,
    options: { batchSize?: number; concurrency?: number } = {},
  ): Promise<R[]> {
    const { batchSize = 10, concurrency = this.config.workerThreads } = options;

    const results: R[] = [];

    for (let i = 0; i < items.length; i += batchSize) {
      const batch = items.slice(i, i + batchSize);

      // Process batch with limited concurrency
      const batchPromises = [];
      for (let j = 0; j < batch.length; j += concurrency) {
        const concurrentBatch = batch.slice(j, j + concurrency);
        const concurrentPromises = concurrentBatch.map(processor);
        batchPromises.push(Promise.all(concurrentPromises));
      }

      const batchResults = await Promise.all(batchPromises);
      results.push(...batchResults.flat());
    }

    return results;
  }

  /**
   * Get performance metrics
   */
  getMetrics(): {
    cache: {
      hits: number;
      misses: number;
      hitRate: number;
      totalOperations: number;
    };
    objectPools: {
      acquisitions: number;
      releases: number;
      efficiency: number;
    };
    memory: {
      gcTriggers: number;
      usage: NodeJS.MemoryUsage;
    };
    caches: Record<string, { size: number; name: string }>;
  } {
    const totalCacheOps = this.metrics.cacheHits + this.metrics.cacheMisses;
    const hitRate =
      totalCacheOps > 0 ? (this.metrics.cacheHits / totalCacheOps) * 100 : 0;

    const poolEfficiency =
      this.metrics.poolAcquisitions > 0
        ? (this.metrics.poolReleases / this.metrics.poolAcquisitions) * 100
        : 0;

    const cacheInfo: Record<string, { size: number; name: string }> = {};
    this.caches.forEach((cache, name) => {
      cacheInfo[name] = { size: cache.size(), name };
    });

    return {
      cache: {
        hits: this.metrics.cacheHits,
        misses: this.metrics.cacheMisses,
        hitRate: Math.round(hitRate * 100) / 100,
        totalOperations: totalCacheOps,
      },
      objectPools: {
        acquisitions: this.metrics.poolAcquisitions,
        releases: this.metrics.poolReleases,
        efficiency: Math.round(poolEfficiency * 100) / 100,
      },
      memory: {
        gcTriggers: this.metrics.gcTriggers,
        usage: process.memoryUsage(),
      },
      caches: cacheInfo,
    };
  }

  /**
   * Reset metrics
   */
  resetMetrics(): void {
    this.metrics = {
      cacheHits: 0,
      cacheMisses: 0,
      poolAcquisitions: 0,
      poolReleases: 0,
      gcTriggers: 0,
    };
  }

  /**
   * Clear all caches and pools
   */
  clearAll(): void {
    this.caches.forEach((cache) => cache.clear());
    this.pools.forEach((pool) => pool.clear());
    this.resetMetrics();
  }

  /**
   * Shutdown and cleanup
   */
  shutdown(): void {
    this.clearAll();
    console.log('üîß Performance enhancer shut down');
  }
}

// Export singleton instance
export const performanceEnhancer = new PerformanceEnhancer();
